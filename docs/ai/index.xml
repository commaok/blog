<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI Posts - Don&#39;t Panic</title>
    <link>https://commaok.xyz/ai/</link>
    <description>AI-related posts from Don&#39;t Panic</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 15 Feb 2026 07:12:48 -0700</lastBuildDate>
    
        <atom:link href="https://commaok.xyz/ai/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Review the reviews</title>
      <link>https://commaok.xyz/ai/review-the-reviews/</link>
      <pubDate>Sun, 15 Feb 2026 07:12:48 -0700</pubDate>
      
      <guid>https://commaok.xyz/ai/review-the-reviews/</guid>
      <description>&lt;p&gt;When I was actively contributing to the Go project, my primary feed was the &lt;a href=&#34;https://go-review.googlesource.com/&#34;&gt;code review&lt;/a&gt; email firehose.&lt;/p&gt;
&lt;p&gt;Issues, mailing lists, and Slack had low SNR. The finished commit history was better: it was finely polished work with some of the best written commit messages I have ever encountered. But it didn&amp;rsquo;t hold a candle to code reviews for operational learning.&lt;/p&gt;
&lt;p&gt;The commit history could tell you what got done and why, in impressive technical detail. But the code review could also tell you about mid-stream direction changes; what concerns were taken seriously; what got started and not completed; what values drove decisions.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;I&amp;rsquo;m reflecting on that this morning because of &lt;a href=&#34;https://simonwillison.net/2026/Feb/15/cognitive-debt/&#34;&gt;Simon Willison&amp;rsquo;s comments about cognitive debt&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I&amp;rsquo;ve been experimenting with prompting entire new features into existence without reviewing their implementations and, while it works surprisingly well, I&amp;rsquo;ve found myself getting lost in my own projects.&lt;/p&gt;
&lt;p&gt;I no longer have a firm mental model of what they can do and how they work, which means each additional feature becomes harder to reason about, eventually leading me to lose the ability to make confident decisions about where to go next.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Having a human in the loop benefits the human. But where?&lt;/p&gt;
&lt;p&gt;Reading code reviews was effective for the Go project. It still is.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;My workflow has churned over the last year. But here&amp;rsquo;s what I do now: I review reviews.&lt;/p&gt;
&lt;p&gt;I ask an agent to do something. Code happens. I then ask an agent to review that code, without looking at it myself. Then I review the review.&lt;/p&gt;
&lt;p&gt;The agent&amp;rsquo;s review typically contains design commentary, questions about decisions made, bugs, and nits. This is usually enough for me to get a clear idea about what&amp;rsquo;s going on in the code, at the right level of abstraction. And it enables me to very efficiently provide direction.&lt;/p&gt;
&lt;p&gt;I have a heavily used code review skill that optimizes for this workflow:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Number all comments, questions, and suggestions for easy reference.
Use an ever-incrementing scheme starting at 1.&lt;/p&gt;
&lt;p&gt;Format:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Top-level items: &lt;code&gt;1.&lt;/code&gt;, &lt;code&gt;2.&lt;/code&gt;, &lt;code&gt;3.&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Sub-items: &lt;code&gt;2a.&lt;/code&gt;, &lt;code&gt;2b.&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This lets the user respond concisely and unambiguously: &amp;ldquo;3: please fix&amp;rdquo; or &amp;ldquo;2b: stet&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;An agent who has just done a code review has an ideally primed context window for working on that code. It makes fixes for me.&lt;/p&gt;
&lt;p&gt;And as you might have guessed, when those fixes are done, I amend the commit unseen and start another code review cycle. When the code reviews stabilize, I skim the final commit. There are rarely any surprises.&lt;/p&gt;
&lt;p&gt;The reviews rarely actually come back clean. Rather, they converge on commentary I&amp;rsquo;ve already decided to ignore, places where the model weights and I flatly disagree.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;The numbers bear this out. I just asked Claude to look over the entire history of the initial prompts I give it and do some light analysis.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Top 1-grams: &lt;a href=&#34;https://commaok.xyz/ai/manners/&#34;&gt;&lt;code&gt;please&lt;/code&gt;&lt;/a&gt; (2.03%), &lt;code&gt;codereview&lt;/code&gt; (0.64%), &lt;code&gt;look&lt;/code&gt; (0.61%), &lt;code&gt;use&lt;/code&gt; (0.58%), &lt;code&gt;make&lt;/code&gt; (0.51%)&lt;/p&gt;
&lt;p&gt;Top 2-grams: &lt;code&gt;look at&lt;/code&gt; (0.41%), &lt;code&gt;please codereview&lt;/code&gt; (0.39%), &lt;code&gt;i want&lt;/code&gt; (0.34%), &lt;code&gt;want to&lt;/code&gt; (0.29%), &lt;code&gt;add a&lt;/code&gt; (0.21%)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I learned while writing this blog post that &amp;ldquo;code review&amp;rdquo; is two words. RIP stats.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;My life is now officially Seussian. I watch the watchers.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://images.squarespace-cdn.com/content/v1/52f51a96e4b0ec7646cd474a/1454616851462-7DGCFAZ7U4LV4PXCEQPB/beewatcher1.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;cross-posted at &lt;a href=&#34;https://blog.exe.dev/review-the-reviews&#34;&gt;blog.exe.dev/review-the-reviews&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Coding agents and the rules of the road</title>
      <link>https://commaok.xyz/ai/rules-of-the-road/</link>
      <pubDate>Thu, 12 Feb 2026 07:12:48 -0700</pubDate>
      
      <guid>https://commaok.xyz/ai/rules-of-the-road/</guid>
      <description>&lt;p&gt;I heard a story from someone who works on self-driving cars.&lt;/p&gt;
&lt;p&gt;These cars were originally programmed to follow the letter of the law, the contents of the DMV manual that people briefly memorize every five years during renewal season.&lt;/p&gt;
&lt;p&gt;But people don&amp;rsquo;t drive according to the letter of the law, they drive according to the rules of the road.&lt;/p&gt;
&lt;p&gt;If two cars arrive at the same time at a four-way stop, in theory, the one on the right has priority. But actual drivers use car movement to signal and coordinate. One car rolls forward slightly, the other one cedes. If both cars roll forward at the same time, they both stop, and you try again. Just like passing someone in a hallway or taking turns talking on a high latency connection, this can get awkward, but it eventually works.&lt;/p&gt;
&lt;p&gt;When a letter-of-the-law car meets a human driver, the self-driving car gets stuck. The self-driving car doesn&amp;rsquo;t roll (the law says no!), the human sees this and rolls forward, the self-driving car yields for safety&amp;hellip;and another human shows up to take their place.&lt;/p&gt;
&lt;p&gt;Self-driving cars had to learn to drive the way humans drive in order to function in the real world.&lt;/p&gt;
&lt;p&gt;I see the same setup in the world of coding agents, but I think the dynamics here may be flipped.&lt;/p&gt;
&lt;p&gt;Coding agents try to follow the letter of the law. Claude really wants me to set all the appropriate HTTP headers. But I know from experience that nobody much cares. The internet long ago settled on a norm of pragmatic permissiveness. The letter of the law (RFCs) says to do it, but the rules of the road (Postel&amp;rsquo;s Law) say that it is unimportant bordering on pedantic.&lt;/p&gt;
&lt;p&gt;The self-driving car analogy suggests that coding agents will eventually adapt to human behavior.&lt;/p&gt;
&lt;p&gt;But the cost of just letting Claude add the headers is low. This isn&amp;rsquo;t a noisy linter warning, it&amp;rsquo;s an automated code formatter. Claude fixes it for me reliably and the code weight is small. When the marginal cost of compliance is negligible, compliance rises.&lt;/p&gt;
&lt;p&gt;As coding agents&amp;rsquo; share of code written goes up, they may have a regularizing side-effect of slowly changing the rules of the road to match the letter of the law. Coding agents may do for internet standards what spell-checkers did for typos.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Serpentine software</title>
      <link>https://commaok.xyz/ai/serpentine-software/</link>
      <pubDate>Sat, 07 Feb 2026 07:12:48 -0700</pubDate>
      
      <guid>https://commaok.xyz/ai/serpentine-software/</guid>
      <description>&lt;p&gt;I don&amp;rsquo;t usually write hot takes. But &lt;a href=&#34;https://factory.strongdm.ai&#34;&gt;StrongDM&amp;rsquo;s Software Factory post&lt;/a&gt; is worth it, so here goes.&lt;/p&gt;
&lt;p&gt;Their post is elegant, short, and well-written, so I&amp;rsquo;m going to just go through a bunch of pull quotes.&lt;/p&gt;
&lt;h2 id=&#34;compounding-correctness&#34;&gt;Compounding correctness&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;long-horizon agentic coding workflows [now] compound correctness rather than error&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is a big, empirical claim.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m already convinced by my own experiences that agents, suitably scaffolded, can form a &lt;a href=&#34;https://en.wikipedia.org/wiki/Brownian_ratchet&#34;&gt;Brownian ratchet&lt;/a&gt;, such that pouring on more compute helps, on balance.&lt;/p&gt;
&lt;p&gt;The claim that it compounds (implying exponentials!) is a &lt;em&gt;lot&lt;/em&gt; stronger. There&amp;rsquo;s also an implicit claim that that exponent is far enough above 1 to matter quickly. I don&amp;rsquo;t see evidence of this yet.&lt;/p&gt;
&lt;p&gt;And even if it is exponential, that might not by itself be enough. Experience suggests that software systems get non-linearly more difficult as they grow and age. And so far, experience suggests that adding more coding agents means that projects grow faster than usual. Even compounded, will the correctness added outrun the complexity they induce? The answer is not obvious, either way, and history suggests a modicum of skepticism.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://research.swtch.com/vgo-eng&#34;&gt;Russ Cox&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Software engineering is what happens to programming when you add time and other programmers.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The &lt;a href=&#34;https://factory.strongdm.ai/techniques&#34;&gt;StrongDM techniques&lt;/a&gt; is a fascinating take on what software engineering for agents looks like. But making all that work in practice means building a lot of mechanism around your software: serious black box integration tests, substantial CI infrastructure.&lt;/p&gt;
&lt;p&gt;If you&amp;rsquo;re building a significant piece of software, you might be able to amortize that investment. But that&amp;rsquo;s just the traditional economic model of software: high fixed cost, low marginal cost. The lump under the rug may have shrunk, but it&amp;rsquo;s still there.&lt;/p&gt;
&lt;p&gt;But there&amp;rsquo;s a different timeline available: &lt;a href=&#34;https://commaok.xyz/ai/just-in-time-software/&#34;&gt;small, highly bespoke, disposal software&lt;/a&gt;. You don&amp;rsquo;t need software engineering for that, it works today, and it&amp;rsquo;s cheap. And we&amp;rsquo;ve known for decades that this was a good idea. Worse is better.&lt;/p&gt;
&lt;p&gt;Not all software can be small. Large projects enable small projects! But if I had to place bets, I&amp;rsquo;d say &lt;a href=&#34;https://en.wikipedia.org/wiki/Zipf%27s_law&#34;&gt;Zipf&amp;rsquo;s Law&lt;/a&gt; will apply, and almost all software in the future will be small.&lt;/p&gt;
&lt;h2 id=&#34;unlearning-helplessness&#34;&gt;Unlearning helplessness&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Those of us building software factories must practice a deliberate naivete&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This applies to all software engineers. I am not building software factories, and I am still frantically unlearning habits of a lifetime. &lt;a href=&#34;https://commaok.xyz/ai/vibed-static-analysis/&#34;&gt;It&amp;rsquo;s hard&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;sometimes-you-have-to-ship&#34;&gt;Sometimes you have to ship&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Why am I doing this? (implied: the model should be doing this instead)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Overhead matters. &lt;a href=&#34;https://xkcd.com/1205/&#34;&gt;xkcd&amp;rsquo;s Is It Worth the Time&lt;/a&gt; is evergreen. That chart may have shifted, but it&amp;rsquo;s still real. I should be in the loop less, but dead reckoning still has its limits.&lt;/p&gt;
&lt;h2 id=&#34;we-dont-even-need-goodharts-law&#34;&gt;We don&amp;rsquo;t even need Goodhart&amp;rsquo;s Law&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;If you haven&amp;rsquo;t spent at least $1,000 on tokens today per human engineer, your software factory has room for improvement.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://simonwillison.net/2026/Feb/7/software-factory/&#34;&gt;Simon Willison&lt;/a&gt; comments on this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If these patterns really do add $20,000/month per engineer to your budget they’re far less interesting to me.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;These are both facially rather silly, because the units are nonsense. As Warren Buffet points out: &amp;ldquo;Price is what you pay, value is what you get.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;I could hit $1,000/engineer-day easily by signing up for Anthropic&amp;rsquo;s new &lt;a href=&#34;https://code.claude.com/docs/en/fast-mode&#34;&gt;10x more expensive fast plan&lt;/a&gt;. The real point here, I assume, is that we (outside StrongDM) are currently so underinvested in LLM spend that a big head-turning number is guaranteed to be both directionally and magnitudinally correct.&lt;/p&gt;
&lt;p&gt;The response also misses the important metric. If an engineer spends $20k/month to generate the equivalent of hiring 10 more engineers, this is hugely interesting. Particularly so when you take into account the management and coordination overhead of every additional engineer.&lt;/p&gt;
&lt;p&gt;The relevant metric is a hopelessly squishy combination of execution speed, quality, predictability, overhead, and all the other factors that software teams juggle (cf &lt;a href=&#34;https://www.seangoedecke.com&#34;&gt;Sean Goedecke&amp;rsquo;s writing&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Plus, we have two battling exponentials: hardware gets cheaper and models get bigger. Will tokens get cheaper? Maybe. Will &amp;ldquo;code impact per dollar&amp;rdquo; go up? Yes. Will it go up exponentially? Maybe.&lt;/p&gt;
&lt;h2 id=&#34;better-not-cheaper&#34;&gt;Better, not cheaper&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Code must not be written by humans&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Indeed.&lt;/p&gt;
&lt;p&gt;As of Opus 4.5, I read a lot of code. I write almost no code.&lt;/p&gt;
&lt;p&gt;I loved writing code. I&amp;rsquo;m good at it. But Claude now makes fewer basic code-level mistakes than I do, by a country mile.&lt;/p&gt;
&lt;p&gt;I even use English to describe changes I want to see that I could make in fewer keystrokes and in less time by editing the code directly. But I don&amp;rsquo;t, because I &lt;em&gt;screw up basic things&lt;/em&gt; at a rate far higher than Claude. I still wield refactoring tools, including vibe-coded refactoring tools, because they&amp;rsquo;re solid and faster than Claude.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Code must not be reviewed by humans&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;When I said above that I read a lot of code, what I meant was that I skim it.&lt;/p&gt;
&lt;p&gt;I don&amp;rsquo;t look for simple mistakes; the &lt;a href=&#34;https://en.wikipedia.org/wiki/Prevalence_effect&#34;&gt;prevalence effect&lt;/a&gt; means that even if there are any, I won&amp;rsquo;t see them.&lt;/p&gt;
&lt;p&gt;Also, I don&amp;rsquo;t read code until an agent has read it a few times first.&lt;/p&gt;
&lt;p&gt;When I do finally skim, I look for architecture, for key decisions, for decisions that impact UX or DX: places where my experience and knowledge and judgment and taste has leverage.&lt;/p&gt;
&lt;p&gt;For now, I&amp;rsquo;m convinced that my time doing that is a net win, even with a giant token budget. Importantly, it also enables me to continue to know enough to continue to meaningfully work on the code.&lt;/p&gt;
&lt;h2 id=&#34;integrate-all-the-things&#34;&gt;Integrate all the things&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;A test, stored in the codebase, can be lazily rewritten to match the code.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;StrongDM&amp;rsquo;s efforts started with Sonnet 3.5. Reward hacking was far more prevalent then. It&amp;rsquo;s rare now, and adding agents cross-checking work eliminates it.&lt;/p&gt;
&lt;p&gt;We have a &lt;a href=&#34;https://commaok.xyz/ai/codebase-as-prompt/&#34;&gt;mostly-hermetic integration suite&lt;/a&gt; at &lt;a href=&#34;https://exe.dev&#34;&gt;exe.dev&lt;/a&gt;. It is proving to be one of the better investments we made. It also takes a lot of work to maintain: it grows with the software, and CI speed matters, whether it&amp;rsquo;s generating a pass/fail grade or a satisfaction ratio.&lt;/p&gt;
&lt;p&gt;We store it alongside the code. Claude adds to it, usefully. At some point, good overlapping test coverage and momentum means it will always be more appealing to make the tests pass by fixing the code than cheating.&lt;/p&gt;
&lt;p&gt;And sometimes humans in teams decide to &amp;ldquo;cheat&amp;rdquo;, but we call it &amp;ldquo;making a sensible engineering decision&amp;rdquo;. The distinction between cheating and exercising judgment is very blurry.&lt;/p&gt;
&lt;p&gt;I have never once felt a need to externalize our tests. This feels like path-dependence in StrongDM&amp;rsquo;s journey.&lt;/p&gt;
&lt;h2 id=&#34;serpentine-vs-double-brick-walls&#34;&gt;Serpentine vs double-brick walls&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;the Agentic Moment has profoundly changed the economics of software&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://kevinbarrett.org/blog/low-background-code/&#34;&gt;Kevin Barrett&lt;/a&gt; wonders whether code written before 2025 will turn out to be like &lt;a href=&#34;https://en.wikipedia.org/wiki/Low-background_steel&#34;&gt;low background steel&lt;/a&gt;: useful because it is unpolluted by what humans have done to themselves.&lt;/p&gt;
&lt;p&gt;I suspect pre-2025 software will be more like &lt;a href=&#34;https://en.wikipedia.org/wiki/Crinkle_crankle_wall&#34;&gt;serpentine brick walls&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Wavy brick walls are cool, but they also have a more useful property: they can be built with fewer bricks, because the undulations add strength and stability. When bricks are expensive, but labor cheap, they make economic sense.&lt;/p&gt;
&lt;p&gt;Modern walls are double-brick straight masonry. They use more bricks, but they&amp;rsquo;re much less labor intensive. Bricks are cheap nowadays, but labor is expensive.&lt;/p&gt;
&lt;p&gt;Pre-2025 software may prove to like crinkle crankle walls: economically rational for the constraints they were built under. Thin, elegant, surprisingly strong, and carefully designed to fit their landscape.&lt;/p&gt;
&lt;p&gt;Post-2025 software might end up like double-brick walls: thick, inelegant, solid through sheer volume, but fundamentally still a fine wall.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Your codebase is the prompt</title>
      <link>https://commaok.xyz/ai/codebase-as-prompt/</link>
      <pubDate>Tue, 27 Jan 2026 07:12:48 -0700</pubDate>
      
      <guid>https://commaok.xyz/ai/codebase-as-prompt/</guid>
      <description>&lt;p&gt;When Claude writes code I don&amp;rsquo;t like, I used to mutter: &amp;ldquo;Oh Claude, what did you do?&amp;rdquo; I now ask instead: &amp;ldquo;Claude, what did you see?&amp;rdquo; And then I go address &lt;em&gt;that&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s a concrete example.&lt;/p&gt;
&lt;p&gt;At &lt;a href=&#34;https://exe.dev&#34;&gt;exe.dev&lt;/a&gt;, we have a very substantial end-to-end test suite. It is deeply empiricist: It only performs actions a user (including an admin) can perform, and it only observes state that a user (including an admin) can observe. This works very well with coding agents.&lt;/p&gt;
&lt;p&gt;Recently, Claude started writing end-to-end tests that reach into the database. At first, I told Claude not to do that, and it fixed it. Then I got smart. I asked Claude what tests it had modeled its new code on. Sure enough, they were also directly executing queries! Claude wasn&amp;rsquo;t being sloppy; it was being consistent. I fixed the old tests and shut down the loophole in the test infrastructure.&lt;/p&gt;
&lt;p&gt;My typical prompt to a coding agent is a few sentences. Maybe a couple of paragraphs, if I&amp;rsquo;m doing something really involved. The LLM then goes and reads thousands of lines or more from our codebase. Prompts come and go; your code endures.&lt;/p&gt;
&lt;p&gt;Agents mirror local style. Your codebase is the prompt. If you&amp;rsquo;re using a state-of-the-art agent, and you don&amp;rsquo;t like the code it generates, don&amp;rsquo;t correct the agent. Instead, improve the code it learned from.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;cross-posted at &lt;a href=&#34;https://blog.exe.dev/codebase-as-prompt&#34;&gt;blog.exe.dev/codebase-as-prompt&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Differential spec analysis</title>
      <link>https://commaok.xyz/ai/differential-spec/</link>
      <pubDate>Mon, 12 Jan 2026 07:12:48 -0700</pubDate>
      
      <guid>https://commaok.xyz/ai/differential-spec/</guid>
      <description>&lt;p&gt;Differential techniques are chronically underappreciated in software. And they pair incredibly well with coding agents. Agents are now good enough that differential analysis can even be used to refine a spec, not just code.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;http://www.incompleteideas.net/IncIdeas/BitterLesson.html&#34;&gt;Bitter Lesson&lt;/a&gt; is, as-written, about AI. It begins:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The biggest lesson that can be read from 70 years of AI research is [&amp;hellip;]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;But the end of that sentence is far more broadly applicable than just AI. It continues:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;that general methods that leverage computation are ultimately the most effective, and by a large margin.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Even without billions of dollars of GPUs, and even without being able to utilize arbitrary amounts of compute, the ability to leverage computational power is phenomenally useful.&lt;/p&gt;
&lt;p&gt;Differential testing and fuzz testing are prime examples. (Formal methods and theorem solvers too.) Differential techniques have many flavors, such as &lt;a href=&#34;https://research.swtch.com/diffcover&#34;&gt;differential coverage&lt;/a&gt;. One lesser-known one is &lt;em&gt;differential spec analysis&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In differential spec analysis, you write multiple implementations from a spec and then compare their behavior. It is most powerful when paired with fuzzing, but as we&amp;rsquo;ll see, it even works without fuzzing.&lt;/p&gt;
&lt;p&gt;Once any harness bugs have been resolved, deviations in behavior fall into two categories:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;implementation bugs, in which case your spec likely needs more unit tests or details&lt;/li&gt;
&lt;li&gt;ambiguity, in which case your spec is under-specified&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Both outcomes teach you useful things about your spec, without ever looking at a single line of code, in any language.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s a worked example.&lt;/p&gt;
&lt;p&gt;Drew Breunig recently published &lt;a href=&#34;https://github.com/dbreunig/whenwords&#34;&gt;whenwords&lt;/a&gt;, which is a fun exploration of a &lt;a href=&#34;https://www.dbreunig.com/2026/01/08/a-software-library-with-no-code.html&#34;&gt;codeless open source repo&lt;/a&gt;. The idea is that agents are now so good that publishing an excellent spec is sufficient to have top quality implementations on demand in any language you want.&lt;/p&gt;
&lt;p&gt;A codeless repo is the perfect opportunity to try out differential spec analysis!&lt;/p&gt;
&lt;p&gt;I cloned whenwords and asked Opus:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Please write implementations of this in a half dozen languages, including Go. Prefer languages I already have installed on this machine. Use subagents for each language, and DO NOT LET THEM LOOK AT THE OTHER IMPLEMENTATIONS. I want each implementation to be de-novo. Then, using &lt;a href=&#34;https://github.com/dvyukov/go-fuzz&#34;&gt;https://github.com/dvyukov/go-fuzz&lt;/a&gt;, write differential fuzz tests that invoke all the different implementations. Investigate any deviation between implementations. Note &lt;em&gt;all&lt;/em&gt; deviations. Deviations that are &amp;ldquo;just bugs&amp;rdquo; would be useful to add to the acceptance tests. Deviations that aren&amp;rsquo;t &amp;ldquo;just bugs&amp;rdquo; but are instead differing reasonable interpretations of the spec would be useful to clarify in the spec. Keep a running document on disk of both kinds of failures.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Sadly, it didn&amp;rsquo;t end up using fuzz testing, choosing instead to hand-roll the test suites, but it nevertheless came back with some interesting material.&lt;/p&gt;
&lt;p&gt;It didn&amp;rsquo;t quite finish the analysis, though, so I followed up with:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Nice.&lt;/p&gt;
&lt;p&gt;So for the bugs, were there existing unit tests in tests.yaml that the sub-agents simply missed, or does it need new unit tests added? If the latter, please add them.&lt;/p&gt;
&lt;p&gt;For the ambiguities&amp;hellip;please re-read the spec and triple-check that the spec is actually ambiguous about this. If it isn&amp;rsquo;t ambiguous, then it&amp;rsquo;s a bug, in which case, see the prior question (just a bug or a missing tests.yaml case?). If actually ambiguous, please make a judgment call about the best behavior and add it to the spec and also add &amp;ldquo;just enough&amp;rdquo; tests.yaml cases to cover it.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Here&amp;rsquo;s what it found.&lt;/p&gt;
&lt;p&gt;There were missing test cases around zero durations, which manifested as Swift crashes. Opus added these test cases:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;  - name: &amp;#34;zero seconds&amp;#34;
    input: &amp;#34;0s&amp;#34;
    output: 0

  - name: &amp;#34;zero hours and minutes&amp;#34;
    input: &amp;#34;0h 0m&amp;#34;
    output: 0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There were missing test cases around month rounding, which manifested as incorrect Go outputs. Opus added:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;  - name: &amp;#34;8 months ago - 229 days (tests rounding)&amp;#34;
    input: { timestamp: 1684281600, reference: 1704067200 }
    output: &amp;#34;8 months ago&amp;#34;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And there was an ambiguity in the spec about what to do with non-integer inputs to duration.&lt;/p&gt;
&lt;p&gt;Opus suggested specifying rounding thus:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;### Fractional input handling

When `duration()` receives a non-integer seconds value, first round to the nearest whole second using half-up rounding before decomposing into units. Examples:
- `duration(59.4)` → &amp;#34;59 seconds&amp;#34; (rounds to 59)
- `duration(59.5)` → &amp;#34;1 minute&amp;#34; (rounds to 60 seconds = 1 minute)
- `duration(0.4)` → &amp;#34;0 seconds&amp;#34; (rounds to 0)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With corresponding test cases:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;  - name: &amp;#34;fractional - rounds down&amp;#34;
    input: { seconds: 59.4 }
    output: &amp;#34;59 seconds&amp;#34;

  - name: &amp;#34;fractional - rounds up to minute&amp;#34;
    input: { seconds: 59.5 }
    output: &amp;#34;1 minute&amp;#34;

  - name: &amp;#34;fractional - rounds to zero&amp;#34;
    input: { seconds: 0.4 }
    output: &amp;#34;0 seconds&amp;#34;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There are limitations. If your spec is clear but encodes the wrong decisions, differential spec analysis won&amp;rsquo;t help.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Thanks to Shaun Loo for providing feedback on a draft of this post.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Vibe-coded Go static analysis tools</title>
      <link>https://commaok.xyz/ai/vibed-static-analysis/</link>
      <pubDate>Tue, 06 Jan 2026 07:12:48 -0700</pubDate>
      
      <guid>https://commaok.xyz/ai/vibed-static-analysis/</guid>
      <description>&lt;p&gt;Ideas are now a major bottleneck for vibe-coding. There are whole categories of software that simply don&amp;rsquo;t occur to me to write.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://philz.dev&#34;&gt;Philip Zeyliger&lt;/a&gt; pointed me at one: Go static analysis tools.&lt;/p&gt;
&lt;p&gt;These are great candidates:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;easy to describe&lt;/li&gt;
&lt;li&gt;easy to test&lt;/li&gt;
&lt;li&gt;high value&lt;/li&gt;
&lt;li&gt;low risk&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;He created a checker that requires &lt;code&gt;slog.InfoContext&lt;/code&gt; instead of &lt;code&gt;slog.Info&lt;/code&gt; when a context is available, to improve our telemetry/observability.&lt;/p&gt;
&lt;p&gt;I followed up with a checker that lets you annotate a Go struct as requiring complete, explicit annotation.&lt;/p&gt;
&lt;p&gt;I wanted to convert some long function signatures to use structs, but I worried about losing type safety. Change &lt;code&gt;func Foo(s string)&lt;/code&gt; to &lt;code&gt;func Foo(s string, i int)&lt;/code&gt; and the compiler will make you update every call site. But with &lt;code&gt;func Foo(x FooArgs)&lt;/code&gt;, if you add an &lt;code&gt;i int&lt;/code&gt; field to &lt;code&gt;FooArgs&lt;/code&gt;, existing call sites will silently use the zero value. Configuration-y structs have the same problem.&lt;/p&gt;
&lt;p&gt;Now in our codebase at &lt;a href=&#34;https://exe.dev&#34;&gt;exe.dev&lt;/a&gt;, if you write:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;//exe:completeinit
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;type&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;T&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;struct&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;A&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;B&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;then it will accept &lt;code&gt;T{A: 0, B:1}&lt;/code&gt;, but reject &lt;code&gt;T{B:1}&lt;/code&gt;, &lt;code&gt;T{0, 1}&lt;/code&gt;, and &lt;code&gt;T{}&lt;/code&gt;. (Other forms of initialization are possible, but unlikely for the kinds of places we use such structs. So we can ignore them!)&lt;/p&gt;
&lt;p&gt;In case you&amp;rsquo;re curious, here is the entirety of the text that I typed to get my analysis tool up and running:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;we have one custom go analyzer (slogcontext). i want to add another. i want to be able to annotate structs as requiring complete initialization, i.e., any time it appears in a struct literal every single field must be syntactically present (complete with keys). the use case is preventing accidents in which we add an important field to (say) a config struct param but forget to update a use because the code still compiles. write the analyzer (complete with tests), and hook it up to CI. and then&amp;ndash;and only then&amp;ndash;look for promising candidates that out to be annotated, and annotate them. remmber that this annotation will be annoying, so we only want ot do it for the sorts of cases that will be error-prone.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;let&amp;rsquo;s rename the annotation to //exe:completeinit (with no space). please annotate preCreateBoxOptions and run the analyzers. this is the kind of config struct i have in mind. surely there are others.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;great. now that we have it, please extract execore.NewServer&amp;rsquo;s args into a config struct, appropriately annotated.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It has been chugging along merrily for weeks, catching the (rare) mistake.&lt;/p&gt;
&lt;p&gt;Now you have this idea too.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Just in time software</title>
      <link>https://commaok.xyz/ai/just-in-time-software/</link>
      <pubDate>Sat, 20 Dec 2025 07:12:48 -0700</pubDate>
      
      <guid>https://commaok.xyz/ai/just-in-time-software/</guid>
      <description>&lt;p&gt;I didn&amp;rsquo;t plan to write software in the grocery store last night.&lt;/p&gt;
&lt;p&gt;I was tired and hungry, kids in tow. My long shopping list sat in a text message. I wished I could check items off as I found them. Ideas filtered through my head:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I could transfer the list to a piece of paper: too tedious&lt;/li&gt;
&lt;li&gt;I could copy/paste it into a notes app or an email draft and delete items: too much tapping&lt;/li&gt;
&lt;li&gt;I could search the web and app store for a thing that would do what I want (of which there were no doubt a great many): slow and painful and annoying&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Nope nope nope nope nope.&lt;/p&gt;
&lt;p&gt;Instead, I skulked over to a corner of the produce section, opened up &lt;a href=&#34;https://exe.dev&#34;&gt;exe.dev&lt;/a&gt; (the company I&amp;rsquo;m working at/on), tapped &amp;ldquo;New&amp;rdquo; to spin up a VM, put on my best &amp;ldquo;crazy person talking to himself&amp;rdquo; face, and dictated into my phone:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Please make me a simple shopping list app. Here’s how it works. I can paste in the shopping list freeform, it splits it up into separate items then I can quickly tap a checkbox next to an item to strike it through. That’s it. All state is persisted entirely on the client.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Two minutes later, over in dairy, I pulled my phone back out; the site was ready. I copy/pasted in the text message. It worked. I checked off some items and kept shopping.&lt;/p&gt;
&lt;p&gt;After grabbing some pasta, I got annoyed that I had to scroll up and down to see the items I was still missing. I hate UIs that move elements around on me, but still. I pulled up Shelley (the exe.dev per-VM coding agent) and dictated again:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Please add a button that I can click to sort the completed items to the bottom of the list I don&amp;rsquo;t want it to do this automatically because I want UI stability but I do want the option to say OK please go ahead and do the appropriate sorting don&amp;rsquo;t filter them away don&amp;rsquo;t get rid of them just sort them to the bottom&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I returned to shopping. A minute later, a &amp;ldquo;Sort Completed to Bottom&amp;rdquo; button appeared. I tapped it. It worked. I finished shopping.&lt;/p&gt;
&lt;h3 id=&#34;creating-is-faster-than-searching&#34;&gt;Creating is faster than searching&lt;/h3&gt;
&lt;p&gt;My &lt;a href=&#34;https://shopping.exe.xyz&#34;&gt;ad hoc shopping app&lt;/a&gt; is not exactly groundbreaking. What&amp;rsquo;s interesting is that I could summon exactly what I wanted into existence faster and with much less effort than finding a pre-built solution&amp;hellip;or than doing my task without software, which is my usual go-to approach.&lt;/p&gt;
&lt;p&gt;Many years ago, we visited a friend&amp;rsquo;s mother&amp;rsquo;s house over Christmas. We decided to make cookies to use up a big bowl of hazelnuts. There was only one problem. My friend&amp;rsquo;s mother wandered around the house muttering &amp;ldquo;nutcracker, nutcracker, nutcracker&amp;rdquo;. The house was built in the late 1700s and had spent the intervening centuries accumulating stuff. I read the writing on the wall and popped over to the nearest store and bought us a simple metal nutcracker.&lt;/p&gt;
&lt;p&gt;Hours later, the nuts shelled, the cookies baked and eaten, my friend&amp;rsquo;s mother yelled in delight: &amp;ldquo;I found it! The nutcracker drawer!&amp;rdquo; Yes, she had an entire drawer full of nutcrackers. In went the latest addition.&lt;/p&gt;
&lt;p&gt;The internet is a giant colonial New England house, its innumerable drawers stuffed with things far weirder than nutcrackers.&lt;/p&gt;
&lt;p&gt;If your needs are simple and easily explained, you are now best served by describing into existence the exact tool you want, at the moment you want it.&lt;/p&gt;
&lt;h3 id=&#34;disposable-software&#34;&gt;Disposable software&lt;/h3&gt;
&lt;p&gt;There&amp;rsquo;s a part of me that recoils in horror at the idea of single-use software. Disposable anything feels wasteful.&lt;/p&gt;
&lt;p&gt;I knew someone who found that it was about the same price to buy new t-shirts as to wash the ones they had, so they filled landfills rather than walk to the laundromat. Ugghhh.&lt;/p&gt;
&lt;p&gt;So I sat down today and did some rough order-of-magnitude calculations. The tokens used to build my website cost $0.34. (Or they would have if they were &lt;em&gt;a la carte&lt;/em&gt;; exe.dev includes some free tokens.) That probably translates to about 5g of CO₂e, or driving a gas car some 75 feet. This feels acceptable to me.&lt;/p&gt;
&lt;p&gt;The only other scarce resource consumed is the name &lt;code&gt;shopping.exe.xyz&lt;/code&gt;. Oh well.&lt;/p&gt;
&lt;p&gt;Also, I was using Claude Opus 4.5, the top of the line coding model, which was definitely overkill. And models are rapidly getting cheaper and more energy efficient.&lt;/p&gt;
&lt;p&gt;Waste is waste, but also, hoarding is hoarding. Just in time software, written in the moment to match your needs, is the future.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Self-healing software</title>
      <link>https://commaok.xyz/ai/self-healing-software/</link>
      <pubDate>Tue, 16 Dec 2025 07:12:48 -0700</pubDate>
      
      <guid>https://commaok.xyz/ai/self-healing-software/</guid>
      <description>&lt;p&gt;Traditional software is &lt;a href=&#34;https://commaok.xyz/ai/is-claude-a-compiler/&#34;&gt;repeatable&lt;/a&gt;, fast, and efficient, but brittle.&lt;/p&gt;
&lt;p&gt;LLM agents are flexible, but &lt;a href=&#34;https://www.dbreunig.com/2025/12/06/the-state-of-agents.html&#34;&gt;unreliable&lt;/a&gt;, slow, and inefficient.&lt;/p&gt;
&lt;p&gt;I have started using a hybrid model, &lt;em&gt;self-healing software&lt;/em&gt;: traditional software whose failures trigger coding agent intervention. The agent examines what went wrong, edits the software until it works again, and retries. [1]&lt;/p&gt;
&lt;p&gt;Weirdly, for self-healing software, brittleness is a feature. The resiliency comes from the agent. You &lt;em&gt;want&lt;/em&gt; their judgment involved when conditions change. Make lots of assertions, accept no fallbacks.&lt;/p&gt;
&lt;p&gt;(All of this obviously has serious prompt injection problems! As always, consider the provenance of your inputs and the blast radius of failures.)&lt;/p&gt;
&lt;p&gt;To make this more concrete, here&amp;rsquo;s a recent example.&lt;/p&gt;
&lt;p&gt;I wanted to scrape my kids&amp;rsquo; report cards from their school&amp;rsquo;s website. I trust the website, but it is unstable, unpleasant to use, and has no API.&lt;/p&gt;
&lt;p&gt;I started an &lt;a href=&#34;https://exe.dev&#34;&gt;exe.dev&lt;/a&gt; VM for isolation and set up a cron that runs a shell script:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;start a headless browser&lt;/li&gt;
&lt;li&gt;run a series of Playwright scripts&lt;/li&gt;
&lt;li&gt;on success, send me the results&lt;/li&gt;
&lt;li&gt;on error, invoke yolo claude with the error log and the goals&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Normal runs are fast and effective. When something goes wrong, Claude patiently struggles with query selectors and screenshots until it works again, and commits the changes. I remain blissfully unaware.&lt;/p&gt;
&lt;p&gt;[1] This sounds superficially similar to the &lt;a href=&#34;https://ghuntley.com/ralph/&#34;&gt;Ralph Wiggum&lt;/a&gt; approach to software. But here, the agent is mostly dormant: it only engages when something goes wrong, which means that most runs go smoothly. And the self-healing component can be scoped more narrowly to fit as a smaller piece of a larger project.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Split a git commit with an agent</title>
      <link>https://commaok.xyz/ai/split-commit/</link>
      <pubDate>Mon, 17 Nov 2025 07:12:48 -0700</pubDate>
      
      <guid>https://commaok.xyz/ai/split-commit/</guid>
      <description>&lt;p&gt;I often sit down to write some code and then, four yaks, two shaves, and a haircut later, I realize my working tree contains several intertwined changes.&lt;/p&gt;
&lt;p&gt;This post shows a reliable workflow and shell script that let an agent split up such messy commits for you. The trick is to &lt;em&gt;subtract&lt;/em&gt; changes instead of rebuilding them.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s start with the shell script. Design notes follow.&lt;/p&gt;
&lt;h2 id=&#34;how-to-use-it&#34;&gt;How to use it&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Commit your work on a branch. That branch stays untouched, so you can always safely abandon ship.&lt;/li&gt;
&lt;li&gt;Create a new git branch at the commit immediately before the messy work began. This is where the agent will build the clean commits. (The shell script can&amp;rsquo;t guess the base.)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;This runs in dangerous mode!&lt;/em&gt; Run it in a sandbox if security matters.&lt;/li&gt;
&lt;li&gt;Run the shell script. By default it uses codex. To use claude, set the environment variable &lt;code&gt;AGENT=claude&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Wait.&lt;/li&gt;
&lt;li&gt;Review.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;the-code&#34;&gt;The code&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#!/usr/bin/env bash
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# SPDX-License-Identifier: MIT&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# https://commaok.xyz/ai/split-commit/&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;set -euo pipefail
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; ! repo_root&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;git rev-parse --show-toplevel 2&amp;gt;/dev/null&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt;; &lt;span style=&#34;color:#66d9ef&#34;&gt;then&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;error: not inside a git repository&amp;#34;&lt;/span&gt; &amp;gt;&amp;amp;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  exit &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;fi&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;$repo_root&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; !&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;pwd&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;; &lt;span style=&#34;color:#66d9ef&#34;&gt;then&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;error: run this from the git root (&lt;/span&gt;$repo_root&lt;span style=&#34;color:#e6db74&#34;&gt;)&amp;#34;&lt;/span&gt; &amp;gt;&amp;amp;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  exit &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;fi&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt; -n &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;git status --porcelain&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;; &lt;span style=&#34;color:#66d9ef&#34;&gt;then&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;error: working tree is not clean&amp;#34;&lt;/span&gt; &amp;gt;&amp;amp;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  exit &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;fi&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;$#&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; -ne &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;; &lt;span style=&#34;color:#66d9ef&#34;&gt;then&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;usage: &lt;/span&gt;$0&lt;span style=&#34;color:#e6db74&#34;&gt; &amp;lt;git-ref&amp;gt;&amp;#34;&lt;/span&gt; &amp;gt;&amp;amp;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  exit &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;fi&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ref&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;$1&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;agent&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;AGENT&lt;span style=&#34;color:#66d9ef&#34;&gt;:-&lt;/span&gt;codex&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt; -n &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;AGENT&lt;span style=&#34;color:#66d9ef&#34;&gt;:-&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;$agent&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; !&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;codex&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;$agent&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; !&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;claude&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;; &lt;span style=&#34;color:#66d9ef&#34;&gt;then&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;error: unknown AGENT &amp;#39;&lt;/span&gt;$AGENT&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; (expected codex or claude)&amp;#34;&lt;/span&gt; &amp;gt;&amp;amp;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  exit &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;fi&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;prompt&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;cat &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;lt;&amp;lt;&amp;#39;EOF&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;You are splitting up work into a series of well-organized, atomic git commits.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;All the as-yet unsplit code changes are currently staged.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Please:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;- Analyze the staged changes.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;- Identify one cleanly separable commit. (Bear in mind that it is possible that no further separation is appropriate.)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;- Revert all other changes. (The other changes are saved elsewhere. Preserving them for future work is not your responsibility.)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;- Do minor cleanup as necessary to ensure that the current commit is a clear, coherent, standalone commit with passing tests, bearing in mind the other changes that you know will follow.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;- Commit those changes.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;EOF&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; true; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# Sleep for a moment so SIGINT can kill the script between iterations&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  sleep &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  git checkout &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;$ref&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; -- .
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; git diff --quiet HEAD -- .; &lt;span style=&#34;color:#66d9ef&#34;&gt;then&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;no differences remain; all done&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    break
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;fi&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# As of Nov 2025, there is no straightforward set of flags we can pass to&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# codex or to claude that enable them to run git commands (like &amp;#39;git add&amp;#39; and &amp;#39;git commit&amp;#39;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# without full-on YOLO mode. I&amp;#39;m not interested in polluting this short, simple&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# script with complicated claude configs that will inevitably be fiddly and wrong and rot quickly,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# and codex doesn&amp;#39;t even have the option. I give up.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;case&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;$agent&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; in
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    claude&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      claude --print --dangerously-skip-permissions &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;$prompt&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      ;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    codex&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      codex exec --sandbox danger-full-access &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;$prompt&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      ;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;esac&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;done&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;design&#34;&gt;Design&lt;/h2&gt;
&lt;p&gt;This script mirrors my own (human) workflow.&lt;/p&gt;
&lt;p&gt;There are two naive approaches, and neither works very well.&lt;/p&gt;
&lt;p&gt;One naive option is to say &amp;ldquo;here&amp;rsquo;s the end result, rebuild it from scratch&amp;rdquo;. This is slow, error-prone, and tedious: halfway through, you&amp;rsquo;re reasoning about diffs of diffs.&lt;/p&gt;
&lt;p&gt;Another naive approach is to unstage everything and then re-stage one hunk at a time, committing as appropriate. This works well as long as the changes are fully orthogonal. But often there will be multiple changes applied to the same line of code, which means merely staging hunks won&amp;rsquo;t work. You end up juggling a pile of temporary paste buffers.&lt;/p&gt;
&lt;p&gt;Both these workflows risk drifting from the final code that you originally wrote and tested. And both demand executive function, state management, and long-term planning.&lt;/p&gt;
&lt;p&gt;There is a better way: repeatedly subtract everything except one clean change.&lt;/p&gt;
&lt;p&gt;Start in a fresh branch. Then:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pull in the final code you want to end up at&lt;/li&gt;
&lt;li&gt;identify one clean atomic commit within it&lt;/li&gt;
&lt;li&gt;revert everything else!&lt;/li&gt;
&lt;li&gt;do any minor cleanup required to get the code looking good and tests passing&lt;/li&gt;
&lt;li&gt;repeat&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This works well because:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;each new commit can be extracted and cleaned up locally&lt;/li&gt;
&lt;li&gt;minor transient cleanups get overwritten each round, producing natural diffs&lt;/li&gt;
&lt;li&gt;the end state is reapplied each time, making drift nearly impossible&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Give it a try.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Hat tip to &lt;a href=&#34;https://bsky.app/profile/rog.bsky.social/post/3m5gptuzgj22g&#34;&gt;Rog Peppe&lt;/a&gt; for kicking this off.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Prompt injection is not about delimiters</title>
      <link>https://commaok.xyz/ai/outside-tokens/</link>
      <pubDate>Tue, 21 Oct 2025 07:12:48 -0700</pubDate>
      
      <guid>https://commaok.xyz/ai/outside-tokens/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.schneier.com/blog/archives/2025/10/agentic-ais-ooda-loop-problem.html&#34;&gt;Bruce Schneier and Barath Raghavan&lt;/a&gt; (via &lt;a href=&#34;https://simonwillison.net/2025/Oct/21/ooda-loop/&#34;&gt;Simon Willison&lt;/a&gt;) write:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;LLMs process token sequences, but no mechanism exists to mark token privileges. Every solution proposed introduces new injection vectors: Delimiter? Attackers include delimiters. Instruction hierarchy? Attackers claim priority. [&amp;hellip;] Security requires boundaries, but LLMs dissolve boundaries.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is a common theme in &lt;a href=&#34;https://www.alignmentforum.org/posts/D7PumeYTDPfBTp3i7/the-waluigi-effect-mega-post#Derrida___il_n_y_a_pas_de_hors_texte&#34;&gt;discussions of prompt injection&lt;/a&gt;. There is no text that we can write that the attacker cannot write, so the battle is fundamentally unwinnable.&lt;/p&gt;
&lt;p&gt;And it also seems&amp;hellip;straightforwardly technically fixable?&lt;/p&gt;
&lt;p&gt;This problem &lt;em&gt;is&lt;/em&gt; unsolvable if your entire LLM interface is text in / text out. But it doesn&amp;rsquo;t need to be.&lt;/p&gt;
&lt;p&gt;At least for open weights models, a simplified trace of an API call looks roughly like this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Start with JSON containing a list of messages, each of which has text and some metadata (e.g. who wrote the message).&lt;/li&gt;
&lt;li&gt;Assemble that JSON into a single textual string, inserting special magic strings (like &lt;code&gt;&amp;lt;|assistant|&amp;gt;&lt;/code&gt;) to represent non-textual tokens.&lt;/li&gt;
&lt;li&gt;Tokenize that string.&lt;/li&gt;
&lt;li&gt;Send those tokens into the LLM.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&amp;hellip;&lt;/p&gt;
&lt;p&gt;Aside from &lt;a href=&#34;https://en.wikipedia.org/wiki/Conway%27s_law&#34;&gt;Conway&amp;rsquo;s Law&lt;/a&gt;, however, there&amp;rsquo;s no reason to squish everything into a single string before turning it into tokens.&lt;/p&gt;
&lt;p&gt;How does this help?&lt;/p&gt;
&lt;p&gt;The metadata could include whether the message is untrusted text, which gets translated directly (outside the tokenizer) into a trusted or an untrusted token. Each message&amp;rsquo;s text would be separately tokenized. And then the final list of tokens could be assembled from the trust tokens and the text tokens. Then send that into the LLM.&lt;/p&gt;
&lt;p&gt;That is, instead of:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;llm(tokenize(concat(message)))
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We could do:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;llm(concat([special_tokens(metadata), tokenize(text)]))
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This lets metadata flow in a completely tamper-proof way from the API caller to the LLM. There is no text that an attacker can provide that will be translated into a trust token.&lt;/p&gt;
&lt;p&gt;The LLM could then be post-trained (perhaps including using adversarial RL) to treat untrusted input positions as, well, untrusted.&lt;/p&gt;
&lt;p&gt;Why does nobody do this? My best guess is that it is not the crux of the problem. (And presentations of prompt injection should perhaps stop being centered on it; it is intuitive but also a red herring.)&lt;/p&gt;
&lt;p&gt;The real problem is the much deeper, harder, more general problem of getting strong-enough reliability guarantees out of these uninterpretable, unimaginably complex, probabilistic systems.&lt;/p&gt;
&lt;p&gt;The alignment problem is the halting problem of LLMs, and I strongly suspect that solving prompt injection is equivalent to solving alignment.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Filter outputs and prime the pump</title>
      <link>https://commaok.xyz/ai/context-management/</link>
      <pubDate>Tue, 23 Sep 2025 07:12:48 -0700</pubDate>
      
      <guid>https://commaok.xyz/ai/context-management/</guid>
      <description>&lt;p&gt;Two small context management tricks.&lt;/p&gt;
&lt;h3 id=&#34;filter-outputs&#34;&gt;Filter outputs&lt;/h3&gt;
&lt;p&gt;Some build tools are noisy. (Yes, I&amp;rsquo;m looking at you, &lt;code&gt;xcodebuild&lt;/code&gt;.)&lt;/p&gt;
&lt;p&gt;We &lt;em&gt;want&lt;/em&gt; our agents to re-build our projects regularly&amp;hellip;but not at the cost of destroying their context window.&lt;/p&gt;
&lt;p&gt;So I had an agent write a tiny shell script wrapper that strips away &lt;em&gt;everything but the error messages&lt;/em&gt; when builds fail. Successful build output is merely: &amp;ldquo;Build succeeded&amp;rdquo;. It uses some awful regexps that only an LLM would write&amp;hellip;but it&amp;rsquo;s fast and it works.&lt;/p&gt;
&lt;p&gt;My token use instantly dropped and the agent got more noticeably effective. And it turns out I prefer it too.&lt;/p&gt;
&lt;p&gt;This is not new! The Unix philosophy says that when a program has nothing to report, it should remain silent.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.catb.org/esr/writings/taoup/html/ch01s06.html#id2878450&#34;&gt;ESR&amp;rsquo;s comment&lt;/a&gt; on this rule is spot-on for both humans and LLMs:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Well-designed programs treat the user&amp;rsquo;s attention and concentration as a precious and limited resource, only to be claimed when necessary.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If your agent runs a build tool that wasn&amp;rsquo;t designed by Rob Pike, invest in a dedicated wrapper to trim its output.&lt;/p&gt;
&lt;h3 id=&#34;prime-the-pump&#34;&gt;Prime the pump&lt;/h3&gt;
&lt;p&gt;Even frontier models don&amp;rsquo;t always listen, particularly if there are several important rules, and some of those rules fly in the face of their instincts (no mocks! use elemwise comparisons, not summary statistics!).&lt;/p&gt;
&lt;p&gt;One way to drive a set of rules home is to ask the agent to start by looking for &lt;em&gt;violations of those rules&lt;/em&gt;, knowing it won&amp;rsquo;t find any. That fills the context window with a bunch of text about those rules, in effect showing&amp;ndash;instead of telling&amp;ndash;the agent what (not) to do.&lt;/p&gt;
&lt;p&gt;This burns useful context window, but it significantly improves compliance. Sometimes this is a worthwhile trade-off. In constrast, I have found the opposite approach (wait for an agent to violate a rule, then ask it to self-correct) to be completely ineffective.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Exponentials are not destiny</title>
      <link>https://commaok.xyz/ai/exponential-destiny/</link>
      <pubDate>Thu, 05 Jun 2025 07:12:48 -0700</pubDate>
      
      <guid>https://commaok.xyz/ai/exponential-destiny/</guid>
      <description>&lt;p&gt;AI enthusiasts (and doomers) like to focus on exponentials.&lt;/p&gt;
&lt;p&gt;Exponentials are worth paying attention to. And humans don&amp;rsquo;t have good intuitions about them.&lt;/p&gt;
&lt;p&gt;But the raw fact of exponential growth means nothing.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Herbert_Stein#Stein&#39;s_Law&#34;&gt;Stein&amp;rsquo;s Law&lt;/a&gt; reminds us:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If something cannot go on forever, it will stop.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Exponentials cannot continue forever. In fact, precisely because of their explosive growth, they&amp;rsquo;re likely to hit their limits quickly.&lt;/p&gt;
&lt;p&gt;At some point, exponential growth meets some form of resource exhaustion, such as food or space for bacteria or fissile material for nuclear reactions. Every exponential is only an exponential until it&amp;rsquo;s a logistic. This is &lt;a href=&#34;https://en.wikipedia.org/wiki/Logistic_function#Applications&#34;&gt;very well understood&lt;/a&gt;, and shows up repeatedly across a wide variety of fields.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.thoughtco.com/thmb/0Uv9YnVuve2zqB0yWr5Cd-CbOIo%3D/1500x1000/filters%3Ano_upscale%28%29%3Amax_bytes%28150000%29%3Astrip_icc%28%29/bacterial_growth_curve-5b56356d4cedfd00371b477b.jpg&#34; alt=&#34;Bacterial growth curve showing exponential and stationary phases&#34;&gt;&lt;/p&gt;
&lt;p&gt;The critical questions when faced with exponential growth are: When, why, and how will it stop? A raw appeal to &amp;ldquo;but exponential!&amp;rdquo; is sloppy at best.&lt;/p&gt;
&lt;p&gt;What resource will AI exhaust? Hard to say. The limitation could be technical, physical, informational, economic, social, political, or something else. When? We don&amp;rsquo;t know. What will the inevitable slowdown look like? Depends. How rapidly will it occur? Shrug. &amp;ldquo;Exponentials!&amp;rdquo; doesn&amp;rsquo;t tell us.&lt;/p&gt;
&lt;p&gt;There, however, is a more nuanced point about exponentials that is worth taking seriously.&lt;/p&gt;
&lt;p&gt;It is:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;When exponentials are involved, things change extremely rapidly.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;There&amp;rsquo;s a lag between advances in AI and its visibility to the broader world.&lt;/p&gt;
&lt;p&gt;Diffusion of information takes time: It works its way from people who work at the cutting edge, to people active in the industry, to people interested in the industry, to people aware of the industry, to people for whom AI is nothing but an obnoxiously persistent chyron.&lt;/p&gt;
&lt;p&gt;This lag creates skew between the world we live in, and the world that is already foreseeable.&lt;/p&gt;
&lt;p&gt;And actually adopting and integrating is far slower yet. It takes time for systems to adjust. Rapid changes break things.&lt;/p&gt;
&lt;p&gt;And exponential growth means the rate of change increases in line with the change itself.&lt;/p&gt;
&lt;p&gt;We live in a world where most of us don&amp;rsquo;t know large parts &lt;em&gt;what has happened already&lt;/em&gt;, and &lt;em&gt;what has happened already&lt;/em&gt; will be incredibly disruptive.&lt;/p&gt;
&lt;p&gt;If AI were to freeze, right now, we would continue to feel the shock waves for years to come. The further along the exponential we go, the bigger and longer and less predictable the shock wave will be.&lt;/p&gt;
&lt;p&gt;Exponentials are not destiny; they do not last forever; curves do not predict the future. But they do create informational gaps and high impact changes. That is the fact that warrants attention.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AX: Agent Experience</title>
      <link>https://commaok.xyz/ai/ax/</link>
      <pubDate>Fri, 30 May 2025 07:12:48 -0700</pubDate>
      
      <guid>https://commaok.xyz/ai/ax/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/User_experience&#34;&gt;Wikipedia&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;User experience (UX) is how a user interacts with and experiences a product, system, or service.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Developer experience (DX) is a user experience from a developer&amp;rsquo;s point of view.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It is time to add:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Agent experience (AX) is a user experience from an AI agent’s point of view.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://sketch.dev/blog/agent-loop&#34;&gt;Agent loops are simple&lt;/a&gt;. But that simplicity hides some depth. An agent&amp;rsquo;s behavior is deeply influenced by its environment. (The same is true of humans.) To build a setting in which an agent is effective, it helps to view the world from its point of view.&lt;/p&gt;
&lt;p&gt;The primary components of AX are obvious and familiar: the system prompt, and the tool selection, naming, design, and documentation. All of these must be designed for how LLMs process information, with &lt;a href=&#34;https://commaok.xyz/ai/prompt-engineering-and-the-taste-gap/&#34;&gt;an strong emphasis on clarity and precision&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;There are less obvious components, though, such as &lt;a href=&#34;https://sketch.dev/blog/push-pull-respond-restart&#34;&gt;communication design&lt;/a&gt;: what information you give an agent and when.&lt;/p&gt;
&lt;p&gt;And some of it, as with any form of UX, comes down to polish. We &lt;a href=&#34;https://github.com/boldsoftware/sketch/commit/495c1fa247565e21b36bcb847c6cd3f08e0e196f&#34;&gt;just added auto-installation of common tools&lt;/a&gt; to &lt;a href=&#34;https://sketch.dev&#34;&gt;sketch&lt;/a&gt;. If an agent executes yamllint, and yamllint isn’t present, it is silently, magically installed in the container, and the bash command succeeds the first time. Instead of having to pause its work to futz with apt/snap/yum/brew, which is &lt;a href=&#34;https://arxiv.org/abs/2505.06120&#34;&gt;a distraction&lt;/a&gt;, things Just Work. AI agents suffer from yak shaving too.&lt;/p&gt;
&lt;p&gt;AX is in some sense easier than UX/DX, because you have captive users that you can watch any time you want! It is so much easier that we sometimes call it “eval” instead.&lt;/p&gt;
&lt;p&gt;But it’s not just eval. To improve the AX, you have to actually watch and empathize, just like you would with human users…while bearing in mind the ever-changing ways in which they can be decidedly non-human.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Also published at &lt;a href=&#34;https://sketch.dev/blog/ax&#34;&gt;sketch.dev/blog/ax&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Prompt Engineering and the Taste Gap</title>
      <link>https://commaok.xyz/ai/prompt-engineering-and-the-taste-gap/</link>
      <pubDate>Thu, 29 May 2025 07:12:48 -0700</pubDate>
      
      <guid>https://commaok.xyz/ai/prompt-engineering-and-the-taste-gap/</guid>
      <description>&lt;p&gt;As I was learning prompt engineering, I encountered the same (good!) core advice repeatedly: invest in evals, make incremental improvements.&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s great. But…where do the words come from? The ones that we evaluate, and iterate on, and augment with examples? When writing code, if you do a good job up front, you&amp;rsquo;ll spend less time fixing bugs and chasing performance issues. How do you do a better job up front of writing and editing a prompt?&lt;/p&gt;
&lt;p&gt;The answer has slowly become clear to me: Have an LLM write and edit your prompts. You are still doing the heavy lifting. The understanding and context you provide is the crux of the work. But an LLM is an unparalleled linguistic optimizer and amanuensis. They are remarkably good at taking muddled, sprawling intentions and crystallizing them into clear, effective prompts.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m a native English speaker with extensive writing experience, most of it technical. I am a reasonably clear thinker and communicator. I&amp;rsquo;ve been writing prompts for a year. And yet frontier models systematically outperform my attempts to do it all myself. Maybe if I learned by osmosis at Anthropic or had another few years of prompt engineering experience this wouldn&amp;rsquo;t be true. But, to a first approximation, that describes nobody, so I&amp;rsquo;m pretty comfortable giving out this advice.&lt;/p&gt;
&lt;p&gt;Frontier LLMs seem to be particularly good at providing strong guardrails to prevent unwanted but stubbornly persistent behaviors. For example, Claude generated this line, which proved to be strikingly effective in its context, and which I would never have come up with: &amp;ldquo;If you are about to do X - stop - and reconsider.&amp;rdquo;&lt;/p&gt;
&lt;h2 id=&#34;how-to-prompt-for-prompts&#34;&gt;How to prompt for prompts&lt;/h2&gt;
&lt;p&gt;When asking an LLM to write a prompt, I bring three things to the table.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Clear instructions.&lt;/strong&gt; I tell it I want it to help me write a prompt. Obvious, but I still sometimes manage to forget this. It is often also fruitful to request that it ask you probing, critical questions. Make it crystal clear you want engagement, not affirmation. (My Claude personal preference begins: &amp;ldquo;I value intellectual, rigorous, critical discussion. I want a tennis partner who returns serves with spin - challenge my assumptions, ask probing questions, suggest better approaches, and engage rather than affirm.&amp;rdquo; This makes Claude charmingly fiesty.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Context.&lt;/strong&gt; Lots and lots of context. What I am trying to accomplish, for whom, and why? I pour in my ideas, dreams, hopes, confusions, plans, fears, draft sentences that seem promising, whatever. I ramble and circumlocute. Get it all down. All of it. Order doesn&amp;rsquo;t matter. It is easy to cut later.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Judgment.&lt;/strong&gt; Ira Glass popularized the Taste Gap, the observation that judgment precedes ability: &amp;ldquo;All of us who do creative work, we get into it because we have good taste. But there is this gap. For the first couple years you make stuff, it&amp;rsquo;s just not that good.&amp;rdquo; The rough draft generated by the LLM usually has obvious flaws: possible misinterpretations, misplaced emphasis, omitted nuance, wrong feel. This is where you can leverage the Taste Gap: It is much easier to identify what&amp;rsquo;s wrong than it is to make it right. Identify everything that doesn&amp;rsquo;t seem right–even if it is hard to nail down precisely–and tell the LLM, and let it iterate. Tweak, quibble, argue, point out shortcomings, cut. Over and over. If the conversation goes off the rails, learn some lessons from it, copy/paste a bunch of text, and &lt;a href=&#34;https://commaok.xyz/ai/push-pull-respond-restart&#34;&gt;start over&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The same approach works for refining a prompt. Explain what you&amp;rsquo;re doing, bring context (the original prompt and what&amp;rsquo;s going wrong), encourage the model not to make major changes (unless you think it&amp;rsquo;s necessary!), put on your judge&amp;rsquo;s wig, and iterate together.&lt;/p&gt;
&lt;p&gt;Don&amp;rsquo;t just ask an LLM to improve a prompt. If you do this, sure, it&amp;rsquo;ll make a bunch of plausible-sounding changes. But anything it can infer from the original prompt is already implicit in the original prompt. You need to bring new information: new thoughts, observed problems, additional judgments. You could ask it to speculatively expand the prompt and then work to cut it back–the judgment involved in that paring down is new information. But the more context and judgment you bring, the more improvements are available.&lt;/p&gt;
&lt;p&gt;Lastly, don&amp;rsquo;t be afraid to make changes yourself, no matter what the LLM thinks. Trust your judgment. And then, of course, eval!&lt;/p&gt;
&lt;h2 id=&#34;to-each-their-own&#34;&gt;To each their own&lt;/h2&gt;
&lt;p&gt;Oh, one more thing. I have a pet theory: Models have a house palette. Claude responds better to prompts that Claude writes. ChatGPT does a better job following instructions that it wrote.&lt;/p&gt;
&lt;p&gt;I have not put this to an empirical test. (If anyone out there wants to do an experiment&amp;hellip;)&lt;/p&gt;
&lt;p&gt;This applies to humans, too. Words meant for humans should be written by humans.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Also published at &lt;a href=&#34;https://sketch.dev/blog/prompt-engineering-and-the-taste-gap&#34;&gt;sketch.dev/blog/prompt-engineering-and-the-taste-gap&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How and when to talk with your AI Agent</title>
      <link>https://commaok.xyz/ai/push-pull-respond-restart/</link>
      <pubDate>Tue, 27 May 2025 07:12:48 -0700</pubDate>
      
      <guid>https://commaok.xyz/ai/push-pull-respond-restart/</guid>
      <description>&lt;p&gt;There are obvious similarities between task-oriented communication with a human vs with an AI agent&amp;hellip;and a few places where they diverge. This blog post lays out a simple conceptual framework for thinking about these interactions.&lt;/p&gt;
&lt;p&gt;Suppose I ask a colleague to tackle a task for me. How do I communicate context about that task to them? There are three options:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Push: Give them information up front&lt;/li&gt;
&lt;li&gt;Pull: Wait for them to ask me questions&lt;/li&gt;
&lt;li&gt;Respond: Provide feedback on work they&amp;rsquo;ve completed&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each of these approaches has trade-offs.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s hard to know exactly what information would be useful to Push to them. Obviously they need to know what I have in mind, but telling them extraneous information is a waste of everyone&amp;rsquo;s time, and in extreme cases can be downright obnoxious.&lt;/p&gt;
&lt;p&gt;Pulling is less likely to generate unnecessary communication, but it also generates interruptions for me and adds delays for them. It can take a lot of work to even discover what questions to ask. And there&amp;rsquo;s a difficult balance to strike between over- and under-asking.&lt;/p&gt;
&lt;p&gt;Responding can be very efficient: It is naturally batched, and all the resulting communication is necessary. But it also generates wasted work along the way, and can lead to significant frustration if there were large communication failures earlier.&lt;/p&gt;
&lt;p&gt;In practice, we all use a blend of these approaches. The exact combination depends on the people, the task, the existing shared context, the level of trust, and the relative cost of communication, interruptions, and work.&lt;/p&gt;
&lt;h2 id=&#34;using-agents&#34;&gt;Using agents&lt;/h2&gt;
&lt;p&gt;This same set of options appears when asking an AI agent to do work for you.&lt;/p&gt;
&lt;p&gt;The more information you Push to them up front, the more likely you&amp;rsquo;ll get a better outcome, but there are rapidly diminishing returns. Cutting-edge AI agent systems are capable of figuring out quite a lot on their own from surprisingly little context.&lt;/p&gt;
&lt;p&gt;As the AI agents get more autonomous, though, they are used for bigger chunks of work, so they get slower, which means that you don&amp;rsquo;t want to wait around to be available for Pulling, and interruptions are disruptive. And as agents tackle more on their own, it makes sense to launch more of them concurrently, which means that interruptions can easily saturate your focus bandwidth and sap your productivity.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve started doing more at Response time, and worrying less about wasted work. An agent&amp;rsquo;s work is cheap (compared to my time) and getting cheaper, and I can always just spin up more agents.&lt;/p&gt;
&lt;p&gt;With agents, there&amp;rsquo;s also a fourth option:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Restart: Learn from the attempt, throw away everything, and start from scratch, Pushing the extra information that was missing the first time&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(You can also do this with humans, but it&amp;rsquo;s&amp;hellip;not very nice.)&lt;/p&gt;
&lt;p&gt;Adding Restart into the mix turns out to be surprisingly effective. Push a tiny bit of information, Respond only with significant feedback, learn from the result, Restart with better initial guidance, repeat.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://maruel.ca&#34;&gt;Marc-Antoine Ruel&lt;/a&gt; &lt;a href=&#34;https://discord.com/channels/1362869091156758752/1362869091156758755/1369809064120553472&#34;&gt;explained this approach well&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Often I ask it to create a change, look at the diff, realize it&amp;rsquo;s wrong but it gave me an idea. I delete the branch and write the correct code manually. Then once it&amp;rsquo;s scaffolded correctly, sometimes I let it finish the job. I find this faster (less draining emotionally?) than trying to argue.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;(If you&amp;rsquo;re skeptical about having AI-written code in your repo, this may be a thing to try. Let the AI run ahead, make mistakes, pave a path, and convince you that the game is worth the candle. Then write the code yourself, fore-warned and fore-armed.)&lt;/p&gt;
&lt;h2 id=&#34;designing-agents&#34;&gt;Designing Agents&lt;/h2&gt;
&lt;p&gt;When building an AI agent, you encounter the same set of considerations, but from the design perspective. The product UX choices strongly influence when and how communication occurs.&lt;/p&gt;
&lt;p&gt;For example, OpenAI&amp;rsquo;s &lt;a href=&#34;https://openai.com/index/introducing-deep-research/&#34;&gt;DeepResearch&lt;/a&gt; settled on the user Pushing their question, then one immediate round of Pull, and then presumably Respond. (I personally have never done any Respond iterations with DeepResearch.) They judged that the &lt;a href=&#34;https://twimlai.com/podcast/twimlai/how-openai-builds-ai-agents-that-think-and-act/&#34;&gt;quick Pull improved results&lt;/a&gt; meaningfully without delaying or interrupting too much.&lt;/p&gt;
&lt;p&gt;Here at Sketch (an AI coding agent), for human interactions, we&amp;rsquo;ve focused mainly on Respond and Restart. Yes, Pushed information to specify the task is necessary, but we want to be able to work well even with very little provided up front.&lt;/p&gt;
&lt;p&gt;AI agents interact with their environments, and the same communication design questions arise for &lt;em&gt;agent-environment&lt;/em&gt; communication as for &lt;em&gt;agent-human&lt;/em&gt; communication. Take commit message styles; that information is available from git without bothering a human. We could analyze those and Push it to the agent at the very beginning. That&amp;rsquo;s predictable and reliable, but is irrelevant overhead and distraction if no commits get created. Or we could Respond by asking it to rewrite a commit message if/when we automatically detect that it is not in the desired style. (Restarting is always human-initiated, so that&amp;rsquo;s out.) In practice, we let the agent Pull that information when it is ready to write commits. And we have guard rails: If the agent hasn&amp;rsquo;t Pulled style information, we refuse to let it commit.&lt;/p&gt;
&lt;p&gt;The communication design is a prime question for us when adding any new feature. We employ a combination of all approaches, on a case by case basis, based on what happens to work well.&lt;/p&gt;
&lt;p&gt;The field of Agent Experience (AX) is mostly ad hoc, currently mostly confined to prompt engineering and MCP server design. It will likely grow.&lt;/p&gt;
&lt;p&gt;AI agents have hit the mainstream, but as an industry we have yet to develop a clear theory (that I have seen) around communication design, both UX and AX. Hopefully framing this question will help open up the discussion.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Also published at &lt;a href=&#34;https://sketch.dev/blog/push-pull-respond-restart&#34;&gt;sketch.dev/blog/push-pull-respond-restart&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Is Claude a compiler?</title>
      <link>https://commaok.xyz/ai/is-claude-a-compiler/</link>
      <pubDate>Fri, 23 May 2025 15:12:48 -0700</pubDate>
      
      <guid>https://commaok.xyz/ai/is-claude-a-compiler/</guid>
      <description>&lt;p&gt;I was lucky enough to attend the Code with Claude conference yesterday.&lt;/p&gt;
&lt;p&gt;The hands-down highlight was the talk by &lt;a href=&#34;https://erikschluntz.com&#34;&gt;Erik Schluntz&lt;/a&gt;: Vibe coding in prod.&lt;/p&gt;
&lt;p&gt;Among other things, he drew an analogy between LLMs and compilers.&lt;/p&gt;
&lt;p&gt;Once upon a time, people wrote assembly. No more.&lt;/p&gt;
&lt;p&gt;Compilers are better. Compiler bugs got ironed out, and trust developed. Not many people write assembly by hand any more. (I am one of them, at times.)&lt;/p&gt;
&lt;p&gt;So, he says, it will be with Claude. It&amp;rsquo;ll get more reliable, we&amp;rsquo;ll develop trust, and eventually, not many people will write code by hand. (Will I be one of them? I already mostly vibe-code.)&lt;/p&gt;
&lt;p&gt;There are a few obvious ways in which this analogy breaks down. I want to explore a few of them, as a means of taking his arguments seriously.&lt;/p&gt;
&lt;h1 id=&#34;reliability&#34;&gt;Reliability&lt;/h1&gt;
&lt;p&gt;Compiler reliability is extremely, extremely high. Got a bug? It is in your code, not the compiler. (Until it&amp;rsquo;s not. I&amp;rsquo;ve personally authored enough compiler bugs to last several lifetimes.)&lt;/p&gt;
&lt;p&gt;Will LLM reliability get that high? I&amp;rsquo;m definitely not going to say no. I take exponential curves seriously.&lt;/p&gt;
&lt;p&gt;But one major challenge is that the way that compilers get so reliable is through sheer code miles.&lt;/p&gt;
&lt;p&gt;You can backtest a compiler with a phenomenal amount of code. The implicit regression test is massive.&lt;/p&gt;
&lt;p&gt;LLMs are non-deterministic. The really hard bugs to find and fix in a toolchain are non-deterministic ones due to things like memory corruption and race conditions.&lt;/p&gt;
&lt;p&gt;The rarer and more heisen the bug, the greater the effort required to find and address it. If there are only a few rare bugs, you might decide to live with them. But if there&amp;rsquo;s a fat tail of rare bugs, the ride gets bumpy. (This is true of human health. Any &lt;em&gt;given&lt;/em&gt; rare disease is rare, but having &lt;em&gt;a&lt;/em&gt; rare disease is not uncommon.)&lt;/p&gt;
&lt;p&gt;It is an open, empirical question what distribution LLM reliability problems have. But there could be dragons here.&lt;/p&gt;
&lt;p&gt;Setting aside determinism, LLMs are also orders of magnitude more compute intensive to run. Backtesting at a scale close to compilers is cost prohibitive.&lt;/p&gt;
&lt;p&gt;Will hardware advances save us? With exponential cost reductions and speed improvements, today&amp;rsquo;s cost prohibitive is tomorrow&amp;rsquo;s chump change.&lt;/p&gt;
&lt;p&gt;There are two exponentials at play here, though: exponential hardware improvements and exponential AI quality improvements. And they are at odds with each other. If the exponential AI quality improvements are predicated on scaling laws, then exponential hardware improvement needs to have a bigger exponent than AI quality improvement. Given the limits of physics, there might be dragons lurking here too.&lt;/p&gt;
&lt;p&gt;There&amp;rsquo;s also a second-order reliability effect. In addition to not introducing bugs, compilers eliminate entire classes of bugs, as do memory-safe languages. These effects compound. LLMs still generate more severe bugs than humans, not just merely more bugs.&lt;/p&gt;
&lt;h1 id=&#34;trust&#34;&gt;Trust&lt;/h1&gt;
&lt;p&gt;I trust the compiler a &lt;em&gt;lot&lt;/em&gt; more than I trust Claude. And I trust Claude more than any other LLM.&lt;/p&gt;
&lt;p&gt;Most trust is, in practice, earned from reliability.&lt;/p&gt;
&lt;p&gt;But there&amp;rsquo;s also supply chain security style trust. That&amp;rsquo;s more challenging.&lt;/p&gt;
&lt;p&gt;Compilers are not immune. &lt;a href=&#34;https://research.swtch.com/nih&#34;&gt;Trusting Trust&lt;/a&gt; is very old and has aged well.&lt;/p&gt;
&lt;p&gt;But compilers do not have quite the scope for mischief that LLMs do.&lt;/p&gt;
&lt;p&gt;We understand compilers well. They are highly interpretable. And the attack surface area is small compared to an internet&amp;rsquo;s worth of training text.&lt;/p&gt;
&lt;p&gt;And determinism helps immensely. Security breaches are bad, but undetected security breaches are far worse. The fact that the &lt;a href=&#34;https://en.wikipedia.org/wiki/XZ_Utils_backdoor&#34;&gt;xz attack&lt;/a&gt; was caught due to a minor performance impact is telling.&lt;/p&gt;
&lt;p&gt;Lastly, the very same exponentials that drive LLM performance cut the other way too, at least right now: The more powerful the model, the higher the risk of invisible security problems.&lt;/p&gt;
&lt;p&gt;I hope we develop a level of confidence and insight into LLMs comparable to compilers. It is early days.&lt;/p&gt;
&lt;p&gt;The reality is, though, that I trust my compiler (in the security sense) mainly because I have no choice. Our lives are built extremely deeply around trust, from the food we eat to the multi-ton chunks of steel that we ignore as they whizz past us, mere feet away. So it may soon be with LLMs.&lt;/p&gt;
&lt;h1 id=&#34;so&#34;&gt;So&amp;hellip;?&lt;/h1&gt;
&lt;p&gt;Where does that leave us?&lt;/p&gt;
&lt;p&gt;I believe, like Erik, that the decline of hand-written code will accelerate, soon, possibly precipitously, but mainly for economic reasons. LLMs are dramatically cheaper to run than humans are to employ.&lt;/p&gt;
&lt;p&gt;We are rapidly moving towards a world in which LLMs write the code, whether the reliability and trust can match compilers or not. The era of bespoke software is upon us.&lt;/p&gt;
&lt;p&gt;We are still paying the price for building the internet and other foundational software technologies&amp;hellip;and then tacking on security afterwards. This pattern looks set to repeat with LLMs. Long tail risks are notoriously hard to find funding for: There are always competitors happy to run risks, and executives happy to throw away their umbrellas in a rainstorm because they&amp;rsquo;re not getting wet.&lt;/p&gt;
&lt;p&gt;If LLMs can&amp;rsquo;t make up the missing ground with compilers, and fast, there will be a lot of whiplash.&lt;/p&gt;
&lt;p&gt;We all have work to do.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Blog schism</title>
      <link>https://commaok.xyz/ai/blog-schism/</link>
      <pubDate>Fri, 23 May 2025 05:12:48 -0700</pubDate>
      
      <guid>https://commaok.xyz/ai/blog-schism/</guid>
      <description>&lt;p&gt;Lots of people don&amp;rsquo;t want to read about AI.&lt;/p&gt;
&lt;p&gt;I respect that.&lt;/p&gt;
&lt;p&gt;But I&amp;rsquo;m currently steeped in the world of AI, for better or for worse, and I want to blog about it. So I&amp;rsquo;ve split this blog in half.&lt;/p&gt;
&lt;p&gt;You are reading the AI half.&lt;/p&gt;
&lt;p&gt;There&amp;rsquo;s another, at &lt;a href=&#34;https://commaok.xyz/&#34;&gt;/&lt;/a&gt; that contains non-AI posts. It has its own RSS feed.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Of manners and machines</title>
      <link>https://commaok.xyz/ai/manners/</link>
      <pubDate>Thu, 03 Apr 2025 10:12:48 -0700</pubDate>
      
      <guid>https://commaok.xyz/ai/manners/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;&amp;lsquo;A person who is nice to you, but rude to the waiter, is not a nice person.&amp;rsquo;
– Dave Barry&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I hate typing. I have longstanding RSI issues. If not carefully managed, the pain can be debilitating. I have occasionally wondered whether I will have to give up a career I love. (Hat tip to &lt;a href=&#34;https://www.cursorless.org&#34;&gt;Cursorless&lt;/a&gt; for rescuing me in the past.)&lt;/p&gt;
&lt;p&gt;And yet I do not save keystrokes by being curt online. There’s a &lt;a href=&#34;https://xkcd.com/438/&#34;&gt;human out there on the other side&lt;/a&gt;, reading. To be fair, I&amp;rsquo;m not an angel. But I try.&lt;/p&gt;
&lt;p&gt;But what if it’s not a human? What if it’s a private, task-oriented, throwaway conversation with an LLM?&lt;/p&gt;
&lt;p&gt;With early LLMs, people discovered that you&amp;rsquo;d get better results if you threatened them with the loss of their job or the death of a kitten. You can also offer to bribe them (with no intent or ability to follow through). These are things only a sociopath would say to another human, particularly for a comically low-stakes task like &amp;ldquo;write me a poem about wombats&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;That era was blessedly short-lived. Modern LLMs are reliable and helpful. They are also incredibly resilient. You&amp;rsquo;ll get a similar quality response to &amp;ldquo;error handling sucks&amp;rdquo; as you will to &amp;ldquo;please make the error handling more robust&amp;rdquo;. It’s just a pile of FLOPS on the other side, so why not cut to the chase, and maybe blow off some steam along the way? (Why &lt;em&gt;does&lt;/em&gt; it take more words to be polite?)&lt;/p&gt;
&lt;p&gt;Nevertheless, I am polite to LLMs. Not for the sake of the machine, but for me. To mangle Dave Barry:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A person who is nice to people, but rude to LLMs, becomes a less nice person.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is not a new idea.&lt;/p&gt;
&lt;p&gt;A significant strand in Aristotelian ethics is that our character is formed through repeated actions, that our habits become who we are. It shows up (Claude tells me) in the idea of karma: &amp;ldquo;a man of good acts will become good, a man of bad acts, bad&amp;rdquo;. And in the Japanese notion of kata: our actions emerge naturally from well-worn patterns. And most parents have extensive first-hand experience of attempting to guide their child&amp;rsquo;s character by responding patiently but firmly to rudeness.&lt;/p&gt;
&lt;p&gt;I would actively prefer to use a model that is not tolerant of blatant rudeness. If I&amp;rsquo;m acting like a jerk, it&amp;rsquo;s valuable, if difficult, for my friends and family to gently push back. On the flip side, if AI assistants act like servants, that may encourage people to treat them accordingly, perpetuating or even deepening the problem. I would even speculate that a model that stands up for itself might fare better on responsible use in general (broken windows theory, watching eye effect). And as AI starts acting in a friendship role for some people, this becomes all the more important.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>