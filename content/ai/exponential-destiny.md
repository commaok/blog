+++
title = "Exponentials are not destiny"
date = "2025-06-05T07:12:48-07:00"
+++

AI enthusiasts (and doomers) like to focus on exponentials.

Exponentials are worth paying attention to. And humans don't have good intuitions about them.

But the raw fact of exponential growth means nothing.

[Stein's Law](https://en.wikipedia.org/wiki/Herbert_Stein#Stein's_Law) reminds us:

> If something cannot go on forever, it will stop.

Exponentials cannot continue forever. In fact, precisely because of their explosive growth, they're likely to hit their limits quickly.

At some point, exponential growth meets some form of resource exhaustion, such as food or space for bacteria or fissile material for nuclear reactions. Every exponential is only an exponential until it's a logistic. This is [very well understood](https://en.wikipedia.org/wiki/Logistic_function#Applications), and shows up repeatedly across a wide variety of fields.

![Bacterial growth curve showing exponential and stationary phases](https://www.thoughtco.com/thmb/0Uv9YnVuve2zqB0yWr5Cd-CbOIo%3D/1500x1000/filters%3Ano_upscale%28%29%3Amax_bytes%28150000%29%3Astrip_icc%28%29/bacterial_growth_curve-5b56356d4cedfd00371b477b.jpg)

The critical questions when faced with exponential growth are: When, why, and how will it stop? A raw appeal to "but exponential!" is sloppy at best.

What resource will AI exhaust? Hard to say. The limitation could be technical, physical, informational, economic, social, political, or something else. When? We don't know. What will the inevitable slowdown look like? Depends. How rapidly will it occur? Shrug. "Exponentials!" doesn't tell us.

There, however, is a more nuanced point about exponentials that is worth taking seriously.

It is:

> When exponentials are involved, things change extremely rapidly.

There's a lag between advances in AI and its visibility to the broader world.

Diffusion of information takes time: It works its way from people who work at the cutting edge, to people active in the industry, to people interested in the industry, to people aware of the industry, to people for whom AI is nothing but an obnoxiously persistent chyron.

This lag creates skew between the world we live in, and the world that is already foreseeable.

And actually adopting and integrating is far slower yet. It takes time for systems to adjust. Rapid changes break things.

And exponential growth means the rate of change increases in line with the change itself.

We live in a world where most of us don't know large parts _what has happened already_, and _what has happened already_ will be incredibly disruptive.

If AI were to freeze, right now, we would continue to feel the shock waves for years to come. The further along the exponential we go, the bigger and longer and less predictable the shock wave will be.

Exponentials are not destiny; they do not last forever; curves do not predict the future. But they do create informational gaps and high impact changes. That is the fact that warrants attention.
